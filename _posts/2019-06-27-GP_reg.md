---
title: "Gaussian Process Regression"
date: 2019-06-27
mathjax: true
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

Gaussian Process Regression is a really flexible way to learn about the parameters of some unknown, unobservable function. When I first came across these I was really confused. I think this mostly to do with the fact that being an Economics student I only ever really learnt about regression from the perspective of frequentist linear regression... also my grasp of linear algebra could be better. Hopefully this guide will be useful to some of you that come from a similar perspective, and I will do my best to illustrate how GP's are actually similar in flavour to other methods of estimating unkown functions such as OLS (which we all know and love). 

Firstly, Gaussian Process Regression is a **Bayesian** approach. This means that we treat parameters in our model as random variables rather than constants. For example, for a statistical model of the following form:

$$\mathbf{y} = \beta \mathbf{X} + \mathbf{u}$$

\beta is now a random variable which has some distribution, for example it may be the case that \(\beta \sim N(0, \sigma^2)\). This is **not** the case in standard frequentist approaches you may have come across in statistics or econometrics classes. 

For a second 

A Gaussian Process is defined completely by it's mean and covariance functions:


We can write out a Gaussian Process like this:

$$f(\bx) \sim GP\big(m(\bx), k(\bx, \bx')  \big)$$
